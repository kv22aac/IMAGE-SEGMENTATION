{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kv22aac/IMAGE-SEGMENTATION/blob/main/IMAGE_SEGMENTATION%5BKV21069118%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ybbBKoQccjDX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from itertools import combinations\n",
        "from collections import Counter\n",
        "from matplotlib_venn import venn2, venn2_circles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Tl9joRuShpQR"
      },
      "outputs": [],
      "source": [
        "#  Load the dataset and examine its structure\n",
        "def load_data(dataset_path):\n",
        "    data = {}\n",
        "    for subset in os.listdir(dataset_path):\n",
        "        subset_path = os.path.join(dataset_path, subset)\n",
        "        if os.path.isdir(subset_path):\n",
        "            data[subset] = {}\n",
        "            if subset == 'test-30':\n",
        "                data[subset]['images'] = [os.path.join(subset_path, img) for img in os.listdir(subset_path) if img.endswith('.jpg')]\n",
        "            else:\n",
        "                labels_file = os.path.join(subset_path, \"labels.json\")\n",
        "                with open(labels_file, 'r') as f:\n",
        "                    data[subset]['labels'] = json.load(f)\n",
        "                images_folder = os.path.join(subset_path, \"data\")\n",
        "                data[subset]['images'] = [os.path.join(images_folder, img) for img in os.listdir(images_folder) if img.endswith('.jpg')]\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GRBWtl-4ILot"
      },
      "outputs": [],
      "source": [
        "#Display subset and Number of images\n",
        "def perform_eda(dataset):\n",
        "    for subset, data in dataset.items():\n",
        "        print(f\"\\n{subset.capitalize()} subset:\")\n",
        "        if subset == 'test-30':\n",
        "            print(f\"Number of images: {len(data['images'])}\")\n",
        "        else:\n",
        "            labels = data['labels']\n",
        "            images = data['images']\n",
        "            # Display class distribution\n",
        "            categories = {category['name']: 0 for category in labels['categories']}\n",
        "            for annotation in labels['annotations']:\n",
        "                categories[labels['categories'][annotation['category_id']]['name']] += 2\n",
        "            print(\"Class Distribution:\")\n",
        "            for category, count in categories.items():\n",
        "                print(f\"{category}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhRM0TJDI3C9",
        "outputId": "2d495e97-9aeb-4887-bf3d-39f47b2cde6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "unzip:  cannot find or open /content/drive/MyDrive/RM_Segmentation_Assignment_dataset (1).zip, /content/drive/MyDrive/RM_Segmentation_Assignment_dataset (1).zip.zip or /content/drive/MyDrive/RM_Segmentation_Assignment_dataset (1).zip.ZIP.\n",
            "\n",
            "Test-30 subset:\n",
            "Number of images: 30\n",
            "\n",
            "Validation-300 subset:\n",
            "Class Distribution:\n",
            "airplane: 10\n",
            "apple: 24\n",
            "backpack: 92\n",
            "banana: 20\n",
            "baseball bat: 12\n",
            "baseball glove: 10\n",
            "bench: 68\n",
            "bicycle: 142\n",
            "bird: 4\n",
            "boat: 90\n",
            "book: 68\n",
            "bottle: 118\n",
            "bowl: 32\n",
            "bus: 220\n",
            "cake: 36\n",
            "car: 1722\n",
            "carrot: 2\n",
            "cat: 14\n",
            "cell phone: 24\n",
            "chair: 248\n",
            "clock: 34\n",
            "couch: 8\n",
            "cup: 124\n",
            "dining table: 136\n",
            "dog: 18\n",
            "donut: 4\n",
            "elephant: 4\n",
            "fire hydrant: 38\n",
            "fork: 48\n",
            "frisbee: 10\n",
            "giraffe: 16\n",
            "handbag: 142\n",
            "horse: 16\n",
            "hot dog: 28\n",
            "kite: 34\n",
            "knife: 54\n",
            "microwave: 2\n",
            "motorcycle: 178\n",
            "orange: 8\n",
            "oven: 4\n",
            "parking meter: 24\n",
            "person: 2382\n",
            "pizza: 200\n",
            "potted plant: 50\n",
            "refrigerator: 4\n",
            "remote: 4\n",
            "sandwich: 2\n",
            "sheep: 6\n",
            "sink: 2\n",
            "skateboard: 22\n",
            "skis: 4\n",
            "snowboard: 2\n",
            "spoon: 24\n",
            "sports ball: 18\n",
            "stop sign: 22\n",
            "suitcase: 70\n",
            "surfboard: 6\n",
            "tennis racket: 24\n",
            "tie: 16\n",
            "traffic light: 390\n",
            "train: 28\n",
            "truck: 254\n",
            "tv: 8\n",
            "umbrella: 62\n",
            "vase: 22\n",
            "wine glass: 38\n",
            "zebra: 2\n",
            "\n",
            "Train-300 subset:\n",
            "Class Distribution:\n",
            "airplane: 30\n",
            "backpack: 168\n",
            "banana: 30\n",
            "baseball bat: 12\n",
            "baseball glove: 24\n",
            "bear: 6\n",
            "bench: 98\n",
            "bicycle: 250\n",
            "bird: 114\n",
            "boat: 40\n",
            "book: 4\n",
            "bottle: 20\n",
            "bowl: 20\n",
            "broccoli: 2\n",
            "bus: 182\n",
            "cake: 26\n",
            "car: 2122\n",
            "carrot: 8\n",
            "cat: 8\n",
            "cell phone: 38\n",
            "chair: 102\n",
            "clock: 34\n",
            "cow: 2\n",
            "cup: 42\n",
            "dining table: 50\n",
            "dog: 28\n",
            "donut: 8\n",
            "elephant: 10\n",
            "fire hydrant: 18\n",
            "fork: 12\n",
            "frisbee: 6\n",
            "giraffe: 2\n",
            "handbag: 144\n",
            "horse: 34\n",
            "hot dog: 6\n",
            "kite: 110\n",
            "knife: 8\n",
            "laptop: 4\n",
            "motorcycle: 146\n",
            "oven: 4\n",
            "parking meter: 18\n",
            "person: 2700\n",
            "pizza: 20\n",
            "potted plant: 18\n",
            "refrigerator: 4\n",
            "remote: 2\n",
            "sandwich: 12\n",
            "scissors: 4\n",
            "skateboard: 60\n",
            "skis: 22\n",
            "spoon: 2\n",
            "sports ball: 46\n",
            "stop sign: 28\n",
            "suitcase: 28\n",
            "surfboard: 30\n",
            "tennis racket: 14\n",
            "tie: 24\n",
            "traffic light: 334\n",
            "train: 20\n",
            "truck: 240\n",
            "umbrella: 136\n",
            "vase: 2\n",
            "wine glass: 4\n"
          ]
        }
      ],
      "source": [
        "# Mounting datset from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip -o \"/content/drive/MyDrive/RM_Segmentation_Assignment_dataset (1).zip\" -d \"/content/drive/MyDrive/unzipped_dataset\"\n",
        "dataset_path = \"/content/drive/MyDrive/unzipped_dataset\"\n",
        "dataset = load_data(dataset_path)\n",
        "perform_eda(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "8Aepv5YCRYwg",
        "outputId": "2a19e711-ab5d-4e33-deb7-2e1fd0814d42"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#  Examine the dataset and look over its layout.\n",
        "def load_data(dataset_path):\n",
        "    data = {}\n",
        "    for subset in os.listdir(dataset_path):\n",
        "        subset_path = os.path.join(dataset_path, subset)\n",
        "        if os.path.isdir(subset_path):\n",
        "            data[subset] = {}\n",
        "            if subset == 'test-30':\n",
        "                data[subset]['images'] = [os.path.join(subset_path, img) for img in os.listdir(subset_path) if img.endswith('.jpg')]\n",
        "            else:\n",
        "                labels_file = os.path.join(subset_path, \"labels.json\")\n",
        "                with open(labels_file, 'r') as f:\n",
        "                    data[subset]['labels'] = json.load(f)\n",
        "                images_folder = os.path.join(subset_path, \"data\")\n",
        "                data[subset]['images'] = [os.path.join(images_folder, img) for img in os.listdir(images_folder) if img.endswith('.jpg')]\n",
        "    return data\n",
        "#Examine the Dataset.\n",
        "dataset_path = '/content/drive/MyDrive/unzipped_dataset'\n",
        "dataset = load_data(dataset_path)\n",
        "\n",
        "# Identify the distribution of classifications.\n",
        "def extract_class_distribution(dataset):\n",
        "    class_distribution = {}\n",
        "    for subset, data in dataset.items():\n",
        "        if subset != 'test-30':\n",
        "            labels = data['labels']\n",
        "            for annotation in labels['annotations']:\n",
        "                category_name = labels['categories'][annotation['category_id']]['name']\n",
        "                if category_name in class_distribution:\n",
        "                    class_distribution[category_name] += 1\n",
        "                else:\n",
        "                    class_distribution[category_name] = 1\n",
        "    return class_distribution\n",
        "\n",
        "class_distribution = extract_class_distribution(dataset)\n",
        "\n",
        "\n",
        "# Figure out correlation heatmap\n",
        "def compute_correlation_heatmap(dataset):\n",
        "    labels_data = []\n",
        "    for subset, data in dataset.items():\n",
        "        if subset != 'test-30':\n",
        "            labels = data['labels']\n",
        "            for annotation in labels['annotations']:\n",
        "                category_name = labels['categories'][annotation['category_id']]['name']\n",
        "                labels_data.append([subset, category_name])\n",
        "\n",
        "    df = pd.DataFrame(labels_data, columns=['Subset', 'Category'])\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    df['Subset'] = le.fit_transform(df['Subset'])\n",
        "    df['Category'] = le.fit_transform(df['Category'])\n",
        "\n",
        "    correlation_matrix = df.corr()\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='viridis', fmt=\".2f\")\n",
        "    plt.title('Correlation Heatmap')\n",
        "    plt.savefig(\"correlation Heatmap.png\",bbox_inches=\"tight\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "compute_correlation_heatmap(dataset)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OdoJFIB-RqIm"
      },
      "outputs": [],
      "source": [
        "# Implement R-CNN model for image segmentation  using TensorFlow\n",
        "def create_rcnn_model(input_shape, num_classes):\n",
        "    base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    model = tf.keras.models.Model(inputs=base_model.input, outputs=x)\n",
        "    return model\n",
        "\n",
        "def preprocess_image(img_path, target_size):\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
        "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img = tf.keras.applications.resnet.preprocess_input(img)\n",
        "    return img\n",
        "\n",
        "def data_generator(dataset, batch_size, target_size):\n",
        "    num_classes = len(dataset['train-300']['labels']['categories'])\n",
        "    while True:\n",
        "      batch_paths = np.random.choice(dataset['train-300']['images'], size=batch_size)\n",
        "      batch_images = []\n",
        "      batch_labels = []\n",
        "\n",
        "      for img_path in batch_paths:\n",
        "        img = preprocess_image(img_path, target_size)\n",
        "        batch_images.append(img)\n",
        "        label = np.zeros(num_classes)\n",
        "        annotations = dataset['train-300']['labels']['annotations']\n",
        "        for annotation in annotations:\n",
        "          if annotation['image_id'] == int(os.path.basename(img_path)[:-4]):\n",
        "            label[annotation['category_id']] = 1\n",
        "        batch_labels.append(label)\n",
        "\n",
        "      yield np.array(batch_images), np.array(batch_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bE-XnC4zSALZ"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "input_shape = (226, 226, 3)\n",
        "num_classes = len(dataset['train-300']['labels']['categories'])\n",
        "batch_size = 40\n",
        "epochs = 50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41Ny_lGQSEuA",
        "outputId": "ffbddcc6-7ae7-4798-a25f-722c85d37e4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Design and build the model\n",
        "model = create_rcnn_model(input_shape, num_classes)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apNA1tE1SJOj",
        "outputId": "8bc9778d-9bf9-49ba-c2d4-278ea8215c30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 20s 2s/step - loss: 0.1833 - accuracy: 0.0107 - val_loss: 0.0146 - val_accuracy: 0.0036\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 12s 2s/step - loss: 0.0125 - accuracy: 0.0036 - val_loss: 0.0245 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.0190 - accuracy: 0.0036 - val_loss: 0.0047 - val_accuracy: 0.0036\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 6s 1s/step - loss: 0.0206 - accuracy: 0.0036 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 0.0139 - accuracy: 0.0929 - val_loss: 0.0066 - val_accuracy: 0.0607\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 0.0075 - accuracy: 0.1179 - val_loss: 0.0066 - val_accuracy: 0.0464\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 6s 990ms/step - loss: 0.0036 - accuracy: 0.0071 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 0.0030 - accuracy: 0.0071 - val_loss: 0.0016 - val_accuracy: 0.0214\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.0026 - accuracy: 0.0036 - val_loss: 7.3320e-04 - val_accuracy: 0.0464\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 6s 1s/step - loss: 0.0011 - accuracy: 0.0571 - val_loss: 7.0070e-04 - val_accuracy: 0.0714\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 7.3710e-04 - accuracy: 0.1893 - val_loss: 4.6076e-04 - val_accuracy: 0.2036\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 6s 1s/step - loss: 0.0012 - accuracy: 0.1857 - val_loss: 5.2994e-04 - val_accuracy: 0.0500\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 7.6674e-04 - accuracy: 0.0107 - val_loss: 5.9671e-04 - val_accuracy: 0.0107\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 7.5979e-04 - accuracy: 0.0036 - val_loss: 4.0129e-04 - val_accuracy: 0.0429\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 1.6537e-04 - accuracy: 0.0286 - val_loss: 3.1318e-04 - val_accuracy: 0.0821\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 6s 1s/step - loss: 2.1400e-04 - accuracy: 0.0929 - val_loss: 2.6785e-04 - val_accuracy: 0.0714\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 7s 1s/step - loss: 2.6724e-04 - accuracy: 0.0607 - val_loss: 2.2563e-04 - val_accuracy: 0.0643\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 6s 1s/step - loss: 2.4086e-04 - accuracy: 0.0929 - val_loss: 1.6264e-04 - val_accuracy: 0.0893\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 7s 1s/step - loss: 1.7664e-04 - accuracy: 0.1750 - val_loss: 1.4340e-04 - val_accuracy: 0.2214\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 6s 999ms/step - loss: 1.6729e-04 - accuracy: 0.1821 - val_loss: 1.1510e-04 - val_accuracy: 0.1250\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 2.4220e-04 - accuracy: 0.1179 - val_loss: 9.5054e-05 - val_accuracy: 0.0714\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 1.9625e-04 - accuracy: 0.0750 - val_loss: 1.3256e-04 - val_accuracy: 0.0821\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 7s 1s/step - loss: 1.8299e-04 - accuracy: 0.0786 - val_loss: 1.2121e-04 - val_accuracy: 0.0429\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 6s 1s/step - loss: 1.2389e-04 - accuracy: 0.0750 - val_loss: 1.3668e-04 - val_accuracy: 0.0750\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 7.9206e-05 - accuracy: 0.1250 - val_loss: 1.0755e-04 - val_accuracy: 0.1536\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 6s 1s/step - loss: 1.2097e-04 - accuracy: 0.1571 - val_loss: 1.2247e-04 - val_accuracy: 0.1571\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 1.3610e-04 - accuracy: 0.1571 - val_loss: 8.2686e-05 - val_accuracy: 0.1607\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 7s 1s/step - loss: 1.2398e-04 - accuracy: 0.0964 - val_loss: 6.1262e-05 - val_accuracy: 0.1179\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 1.0298e-04 - accuracy: 0.1571 - val_loss: 8.4078e-05 - val_accuracy: 0.1250\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 6.0060e-05 - accuracy: 0.1643 - val_loss: 1.2744e-04 - val_accuracy: 0.1893\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 5.8334e-05 - accuracy: 0.1821 - val_loss: 7.5333e-05 - val_accuracy: 0.1286\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 6.5252e-05 - accuracy: 0.1857 - val_loss: 6.5588e-05 - val_accuracy: 0.1607\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 6s 1s/step - loss: 7.0464e-05 - accuracy: 0.1500 - val_loss: 7.0837e-05 - val_accuracy: 0.1286\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 7s 1s/step - loss: 6.2330e-05 - accuracy: 0.1464 - val_loss: 5.0367e-05 - val_accuracy: 0.0893\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 6s 1s/step - loss: 6.8811e-05 - accuracy: 0.1429 - val_loss: 6.0291e-05 - val_accuracy: 0.1607\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 6.3886e-05 - accuracy: 0.1571 - val_loss: 6.1330e-05 - val_accuracy: 0.2607\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 7.5356e-05 - accuracy: 0.1964 - val_loss: 6.0420e-05 - val_accuracy: 0.1857\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 4.4735e-05 - accuracy: 0.1679 - val_loss: 5.7050e-05 - val_accuracy: 0.2250\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 6s 1s/step - loss: 5.9246e-05 - accuracy: 0.2571 - val_loss: 9.5886e-05 - val_accuracy: 0.2321\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 4.1194e-05 - accuracy: 0.2071 - val_loss: 4.3863e-05 - val_accuracy: 0.1893\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 4.8984e-05 - accuracy: 0.1821 - val_loss: 4.5042e-05 - val_accuracy: 0.2250\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 6s 1s/step - loss: 6.9854e-05 - accuracy: 0.2286 - val_loss: 6.1347e-05 - val_accuracy: 0.2071\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 4.9370e-05 - accuracy: 0.0964 - val_loss: 5.2432e-05 - val_accuracy: 0.1250\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 6.3260e-05 - accuracy: 0.1500 - val_loss: 4.2889e-05 - val_accuracy: 0.1214\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 7s 1s/step - loss: 6.1262e-05 - accuracy: 0.1857 - val_loss: 5.3482e-05 - val_accuracy: 0.2036\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 11s 2s/step - loss: 3.6649e-05 - accuracy: 0.2286 - val_loss: 4.9462e-05 - val_accuracy: 0.2429\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 4.9556e-05 - accuracy: 0.2179 - val_loss: 3.4775e-05 - val_accuracy: 0.3143\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 6s 1s/step - loss: 5.1398e-05 - accuracy: 0.2679 - val_loss: 1.7631e-05 - val_accuracy: 0.2107\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 7s 1s/step - loss: 4.9200e-05 - accuracy: 0.2321 - val_loss: 4.0254e-05 - val_accuracy: 0.1500\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 6s 1s/step - loss: 3.8434e-05 - accuracy: 0.1786 - val_loss: 4.4032e-05 - val_accuracy: 0.1357\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "train_steps = len(dataset['train-300']['images']) // batch_size\n",
        "validation_steps = len(dataset['validation-300']['images']) // batch_size\n",
        "train_generator = data_generator(dataset, batch_size, (input_shape[0], input_shape[1]))\n",
        "validation_generator = data_generator(dataset, batch_size, (input_shape[0], input_shape[1]))\n",
        "history = model.fit(train_generator, steps_per_epoch=train_steps, epochs=epochs, validation_data=validation_generator, validation_steps=validation_steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXmwBEISYDtK",
        "outputId": "2880a1c3-6dfa-460b-e8a6-5e763b00c6d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        }
      ],
      "source": [
        "def predict_test_data(model, test_images):\n",
        "    predictions = []\n",
        "    for img_path in test_images:\n",
        "        img = preprocess_image(img_path, (226, 226))\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        prediction = model.predict(img)\n",
        "        predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "# Load test images\n",
        "test_images = dataset['test-30']['images']\n",
        "\n",
        "# Make predictions on test data\n",
        "predictions = predict_test_data(model, test_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfQ_sKWhZZU2",
        "outputId": "0b2896b0-3954-4bcb-8ef9-f19ab822fa81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Warning: Predicted class index 59 is not in the expected range.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Warning: Predicted class index 59 is not in the expected range.\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Warning: Predicted class index 59 is not in the expected range.\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Warning: Predicted class index 16 is not in the expected range.\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Warning: Predicted class index 43 is not in the expected range.\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Warning: Predicted class index 41 is not in the expected range.\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Warning: Predicted class index 16 is not in the expected range.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Warning: Predicted class index 16 is not in the expected range.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Warning: Predicted class index 57 is not in the expected range.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Warning: Predicted class index 16 is not in the expected range.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Warning: Predicted class index 16 is not in the expected range.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Warning: Predicted class index 59 is not in the expected range.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Warning: Predicted class index 16 is not in the expected range.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Warning: Predicted class index 59 is not in the expected range.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Warning: Predicted class index 16 is not in the expected range.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Warning: Predicted class index 59 is not in the expected range.\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Warning: Predicted class index 56 is not in the expected range.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Warning: Predicted class index 59 is not in the expected range.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Warning: Predicted class index 16 is not in the expected range.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Warning: Predicted class index 43 is not in the expected range.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Warning: Predicted class index 16 is not in the expected range.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Warning: Predicted class index 41 is not in the expected range.\n",
            "Image 1: person\n",
            "Image 2: Unknown\n",
            "Image 3: Unknown\n",
            "Image 4: Unknown\n",
            "Image 5: Unknown\n",
            "Image 6: Unknown\n",
            "Image 7: Unknown\n",
            "Image 8: person\n",
            "Image 9: person\n",
            "Image 10: Unknown\n",
            "Image 11: Unknown\n",
            "Image 12: person\n",
            "Image 13: Unknown\n",
            "Image 14: Unknown\n",
            "Image 15: Unknown\n",
            "Image 16: Unknown\n",
            "Image 17: person\n",
            "Image 18: person\n",
            "Image 19: Unknown\n",
            "Image 20: Unknown\n",
            "Image 21: Unknown\n",
            "Image 22: person\n",
            "Image 23: Unknown\n",
            "Image 24: Unknown\n",
            "Image 25: person\n",
            "Image 26: Unknown\n",
            "Image 27: Unknown\n",
            "Image 28: Unknown\n",
            "Image 29: Unknown\n",
            "Image 30: Unknown\n"
          ]
        }
      ],
      "source": [
        "# Function to perform inference on test images\n",
        "def predict_classes(model, test_images):\n",
        "    classes = {0: 'person', 1: 'car', 2: 'dog', 3: 'cake'}\n",
        "    predictions = []\n",
        "    for img_path in test_images:\n",
        "        img = preprocess_image(img_path, (226, 226))\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        prediction = model.predict(img)\n",
        "        predicted_class = np.argmax(prediction)\n",
        "        if predicted_class not in classes:\n",
        "            print(f\"Warning: Predicted class index {predicted_class} is not in the expected range.\")\n",
        "            predictions.append('Unknown')\n",
        "        else:\n",
        "            predictions.append(classes[predicted_class])\n",
        "    return predictions\n",
        "\n",
        "# Path to test images\n",
        "test_images_path = \"/content/drive/MyDrive/imgs/test-30\"\n",
        "\n",
        "# Get list of test image paths\n",
        "test_image_paths = [os.path.join(test_images_path, img) for img in os.listdir(test_images_path) if img.endswith('.jpg')]\n",
        "\n",
        "# Perform inference on test images\n",
        "test_predictions = predict_classes(model, test_image_paths)\n",
        "\n",
        "# Print the predicted classes of test images\n",
        "for i, prediction in enumerate(test_predictions):\n",
        "    print(f\"Image {i+1}: {prediction}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfX-l7IqZ8Ra",
        "outputId": "ebf92afe-fe20-46dd-da75-8e38133af7df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "Warning: Predicted class index 0 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001751.jpg.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Warning: Predicted class index 59 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001380.jpg.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Warning: Predicted class index 59 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001643.jpg.\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Warning: Predicted class index 59 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001482.jpg.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicted Class for /content/drive/MyDrive/imgs/test-30/000000001594.jpg: car\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Warning: Predicted class index 43 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001551.jpg.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Predicted Class for /content/drive/MyDrive/imgs/test-30/000000001685.jpg: person\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Warning: Predicted class index 0 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001583.jpg.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Warning: Predicted class index 0 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001654.jpg.\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Predicted Class for /content/drive/MyDrive/imgs/test-30/000000001494.jpg: car\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicted Class for /content/drive/MyDrive/imgs/test-30/000000001411.jpg: car\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Warning: Predicted class index 0 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001459.jpg.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Warning: Predicted class index 57 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001730.jpg.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Predicted Class for /content/drive/MyDrive/imgs/test-30/000000001717.jpg: car\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicted Class for /content/drive/MyDrive/imgs/test-30/000000001410.jpg: car\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Warning: Predicted class index 59 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001385.jpg.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Warning: Predicted class index 0 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001600.jpg.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Warning: Predicted class index 0 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001492.jpg.\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicted Class for /content/drive/MyDrive/imgs/test-30/000000001657.jpg: car\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Warning: Predicted class index 59 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001671.jpg.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicted Class for /content/drive/MyDrive/imgs/test-30/000000001418.jpg: car\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Warning: Predicted class index 0 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001444.jpg.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Warning: Predicted class index 59 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001653.jpg.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Warning: Predicted class index 56 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001702.jpg.\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Warning: Predicted class index 0 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001550.jpg.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Warning: Predicted class index 59 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001650.jpg.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Predicted Class for /content/drive/MyDrive/imgs/test-30/000000001750.jpg: car\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Warning: Predicted class index 43 is not in the expected range for image /content/drive/MyDrive/imgs/test-30/000000001371.jpg.\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Predicted Class for /content/drive/MyDrive/imgs/test-30/000000001773.jpg: car\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicted Class for /content/drive/MyDrive/imgs/test-30/000000001439.jpg: person\n",
            "Accuracy: 0.36666666666666664\n"
          ]
        }
      ],
      "source": [
        "# Function to extract class keys from JSON file\n",
        "def extract_class_keys(json_file_path):\n",
        "    with open(json_file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    class_keys = {}\n",
        "    for category in data['categories']:\n",
        "        if category['name'] in ['person', 'car', 'dog', 'cake']:\n",
        "            class_keys[category['id']] = category['name']\n",
        "    return class_keys\n",
        "\n",
        "# Function to evaluate the model on test images\n",
        "def evaluate_model(model, test_images, class_keys):\n",
        "    num_correct = 0\n",
        "    total_images = len(test_images)\n",
        "\n",
        "    for img_path in test_images:\n",
        "      img = preprocess_image(img_path, (226, 226))\n",
        "      img = np.expand_dims(img, axis=0)\n",
        "      prediction = model.predict(img)\n",
        "      predicted_class = np.argmax(prediction)\n",
        "\n",
        "      if predicted_class not in class_keys:\n",
        "        print(f\"Warning: Predicted class index {predicted_class} is not in the expected range for image {img_path}.\")\n",
        "      else:\n",
        "        predicted_label = class_keys[predicted_class]\n",
        "        print(f\"Predicted Class for {img_path}: {predicted_label}\")\n",
        "        num_correct += 1\n",
        "    accuracy = num_correct / total_images\n",
        "    return accuracy\n",
        "# Load class keys from JSON file\n",
        "json_file_path = \"/content/drive/MyDrive/imgs/train-300/labels.json\"  # Update with the path to your labels.json file\n",
        "class_keys = extract_class_keys(json_file_path)\n",
        "\n",
        "# Evaluate the model on test images and print accuracy\n",
        "accuracy = evaluate_model(model, test_image_paths, class_keys)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1BKSSPR-L6RU_oJIcu0L07vw3yiRFFQU5",
      "authorship_tag": "ABX9TyPVIb/mkmGReiLTp/aHWDiy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}